{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference to https://jackiexiao.github.io/eat_pytorch_in_20_days/5.%E4%B8%AD%E9%98%B6API/5-4%2CTensorBoard%E5%8F%AF%E8%A7%86%E5%8C%96/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchkeras import Model, summary\n",
    "import datetime\n",
    "\n",
    "logs_dir_root = \"./logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size = 3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2,stride = 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5)\n",
    "        self.dropout = nn.Dropout2d(p = 0.1)\n",
    "        self.adaptive_pool = nn.AdaptiveMaxPool2d((1,1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(64,32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(32,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        y = self.sigmoid(x)\n",
    "        return y\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "summary(net, input_shape= (3, 32, 32))\n",
    "timestamp = \"{0:%Y%m%d_%H%M%S/}\".format(datetime.datetime.now())\n",
    "logs_dir = f\"./{logs_dir_root}/tensorboard_sigmods/{timestamp}\"\n",
    "writer = SummaryWriter(logs_dir)\n",
    "\n",
    "writer.add_graph(net, input_to_model = torch.rand(1, 3, 32, 32))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# f(x) = a*x**2 + b*x + c的最小值\n",
    "x = torch.tensor(0.0, requires_grad = True) # x需要被求导\n",
    "a = torch.tensor(1.0)\n",
    "b = torch.tensor(-2.0)\n",
    "c = torch.tensor(0.5)\n",
    "\n",
    "optimizer = torch.optim.SGD(params=[x],lr = 0.01)\n",
    "\n",
    "def f(x):\n",
    "    result = a*torch.pow(x,2) + b*x + c \n",
    "    return(result)\n",
    "\n",
    "timestamp = \"{0:%Y%m%d_%H%M%S/}\".format(datetime.datetime.now())\n",
    "logs_dir = f'{logs_dir_root}/funcx/{timestamp}'\n",
    "writer = SummaryWriter(logs_dir)\n",
    "for i in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    y = f(x)\n",
    "    y.backward()\n",
    "    optimizer.step()\n",
    "    writer.add_scalar(\"x\", x.item(), i) #日志中记录x在第step i 的值\n",
    "    writer.add_scalar(\"y\", y.item(), i) #日志中记录y在第step i 的值\n",
    "\n",
    "writer.close()\n",
    "print(\"y =\", f(x).data, \";\" , \"x =\", x.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "\n",
    "# create a normalized distribution matrix\n",
    "def norm(mean, std):\n",
    "    t = std * torch.randn((100, 20)) + mean\n",
    "    return t\n",
    "timestamp = \"{0:%Y%m%d_%H%M%S/}\".format(datetime.datetime.now())\n",
    "logs_dir = f'{logs_dir_root}/distribution/{timestamp}'\n",
    "writer = SummaryWriter(logs_dir)\n",
    "\n",
    "for step, mean in enumerate(range(-10, 10, 1)):\n",
    "    w = norm(mean, 1)\n",
    "    writer.add_histogram(\"w\", w, step)\n",
    "    writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "transform_train = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor()])\n",
    "transform_valid = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"./data/\"\n",
    "# # when set download=True, download error(SSLCertVerificationError), so I download manually via http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and\n",
    "# # then cd ${data_cifar10} and tar zxf cifar-10-python.tar.gz\n",
    "data_cifar10 = f'{data_root}/cifar10/'\n",
    "print(data_cifar10)\n",
    "ds_train = torchvision.datasets.CIFAR10(root=data_cifar10, train=True, download=False, transform=transform_train)\n",
    "ds_valid = torchvision.datasets.CIFAR10(root=data_cifar10, train=False, download=False, transform=transform_valid)\n",
    "# \n",
    "data_cifar100 = f'{data_root}/cifar100/'\n",
    "# download url http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
    "# cd ${data_cifar100} and tar zxf cifar-100-python.tar.gz\n",
    "ds_train = torchvision.datasets.CIFAR100(root=data_cifar100, train=True, download=False, transform=transform_train)\n",
    "ds_valid = torchvision.datasets.CIFAR100(root=data_cifar100, train=False, download=False, transform=transform_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_train.class_to_idx)\n",
    "\n",
    "dl_train = DataLoader(ds_train,batch_size = 50,shuffle = True,num_workers=3)\n",
    "dl_valid = DataLoader(ds_valid,batch_size = 50,shuffle = True,num_workers=3)\n",
    "\n",
    "dl_train_iter = iter(dl_train)\n",
    "images, labels = dl_train_iter.next()\n",
    "\n",
    "timestamp = \"{0:%Y%m%d_%H%M%S}/\".format(datetime.datetime.now())\n",
    "logs_dir = f\"{logs_dir_root}/visualize_raw_img/{timestamp}\"\n",
    "writer = SummaryWriter(logs_dir)\n",
    "\n",
    "# display a raw image\n",
    "writer.add_image('images[0]', images[0])\n",
    "writer.close()\n",
    "\n",
    "# 将多张图片拼接成一张图片，中间用黑色网格分割\n",
    "# concat multipule images to one\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image('image_grid', img_grid)\n",
    "writer.close()\n",
    "\n",
    "writer.add_images(\"images\", images, global_step = 0)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "figure = plt.figure(figsize=(8,8)) \n",
    "for i in range(9):\n",
    "    img,label = ds_train[i]\n",
    "    img = img.permute(1,2,0)\n",
    "    ax=plt.subplot(3,3,i+1)\n",
    "    ax.imshow(img.numpy())\n",
    "    ax.set_title(\"label = %d\"%label)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([]) \n",
    "plt.show()\n",
    "\n",
    "timestamp = \"{0:%Y%m%d_%H%M%S}/\".format(datetime.datetime.now())\n",
    "logs_dir = f'{logs_dir_root}/visualize_manually_plot/{timestamp}'\n",
    "writer = SummaryWriter(logs_dir)\n",
    "writer.add_figure('figure', figure, global_step=0)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference to https://stackoverflow.com/questions/55970686/tensorboard-not-found-as-magic-function-in-jupyter\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {logs_dir_root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() # read data from ~\\AppData\\Local\\Temp\\.tensorboard-info on windows\n",
    "notebook.start(f\"--logdir {logs_dir_root}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82043e9c6bb60dc85d822aa1bc58ee389a3953da33585b1a533ca4c796d4eb5e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
